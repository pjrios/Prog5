{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79857216-c12c-4ef2-8589-bbc1b8cb8fd8",
   "metadata": {},
   "source": [
    "# Yolo v11 y arduino\n",
    "\n",
    "En este proyecto, se explora la integración de YOLO v11, un avanzado modelo para la detección de objetos, con Arduino. La combinación de ambas tecnologías permite desarrollar sistemas que reconocen objetos y luego envían esta información a un dispositivo embebido para su utilización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2aa01-2226-451e-ba29-7feb9f84d55a",
   "metadata": {},
   "source": [
    "### Clases disponibles\n",
    "\n",
    "Esta sección presenta una lista de clases de objetos que el modelo YOLO v11 puede identificar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f4d401-8c63-475c-9c68-10aa89d8a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"persona\",\n",
    "    \"bicicleta\",\n",
    "    \"coche\",\n",
    "    \"moto\",\n",
    "    \"avión\",\n",
    "    \"autobús\",\n",
    "    \"tren\",\n",
    "    \"camión\",\n",
    "    \"barco\",\n",
    "    \"semáforo\",\n",
    "    \"boca de incendios\",\n",
    "    \"señal de stop\",\n",
    "    \"parquímetro\",\n",
    "    \"banco\",\n",
    "    \"pájaro\",\n",
    "    \"gato\",\n",
    "    \"perro\",\n",
    "    \"caballo\",\n",
    "    \"oveja\",\n",
    "    \"vaca\",\n",
    "    \"elefante\",\n",
    "    \"oso\",\n",
    "    \"cebra\",\n",
    "    \"jirafa\",\n",
    "    \"mochila\",\n",
    "    \"paraguas\",\n",
    "    \"bolso\",\n",
    "    \"corbata\",\n",
    "    \"maleta\",\n",
    "    \"frisbee\",\n",
    "    \"esquís\",\n",
    "    \"snowboard\",\n",
    "    \"pelota de deporte\",\n",
    "    \"cometa\",\n",
    "    \"bate de béisbol\",\n",
    "    \"guante de béisbol\",\n",
    "    \"monopatín\",\n",
    "    \"tabla de surf\",\n",
    "    \"raqueta de tenis\",\n",
    "    \"botella\",\n",
    "    \"copa de vino\",\n",
    "    \"taza\",\n",
    "    \"tenedor\",\n",
    "    \"cuchillo\",\n",
    "    \"cuchara\",\n",
    "    \"bol\",\n",
    "    \"plátano\",\n",
    "    \"manzana\",\n",
    "    \"sándwich\",\n",
    "    \"naranja\",\n",
    "    \"brócoli\",\n",
    "    \"zanahoria\",\n",
    "    \"perrito caliente\",\n",
    "    \"pizza\",\n",
    "    \"donut\",\n",
    "    \"pastel\",\n",
    "    \"silla\",\n",
    "    \"sofá\",\n",
    "    \"planta en maceta\",\n",
    "    \"cama\",\n",
    "    \"mesa de comedor\",\n",
    "    \"inodoro\",\n",
    "    \"televisor\",\n",
    "    \"portátil\",\n",
    "    \"ratón\",\n",
    "    \"mando a distancia\",\n",
    "    \"teclado\",\n",
    "    \"teléfono móvil\",\n",
    "    \"microondas\",\n",
    "    \"horno\",\n",
    "    \"tostadora\",\n",
    "    \"fregadero\",\n",
    "    \"nevera\",\n",
    "    \"libro\",\n",
    "    \"reloj\",\n",
    "    \"jarrón\",\n",
    "    \"tijeras\",\n",
    "    \"oso de peluche\",\n",
    "    \"secador de pelo\",\n",
    "    \"cepillo de dientes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25cc883-61a8-49b9-bdd8-99b325061b11",
   "metadata": {},
   "source": [
    "### Importar librerias\n",
    "\n",
    "Para comenzar a trabajar con el modelo YOLO v11, es necesario importar varias librerías esenciales. Se utilizaran ultralytics para el uso del modelo YOLO y cv2 de OpenCV para el procesamiento de imágenes y videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652ecb01-7840-42a6-ab93-791b0cf68ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d3f6e-49b3-4e59-8410-1bcb4ddf1a0f",
   "metadata": {},
   "source": [
    "### Función para predecir\n",
    "\n",
    "Esta sección utiliza el modelo YOLO v11 para realizar predicciones sobre imágenes o videos.Comenzamos al de cargar una imagen o video para entonces usar el modelo para detectar y clasificar los objetos presentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906e9cf0-8b46-4e62-ba83-47b5f415f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir objetos en una imagen usando un modelo YOLO\n",
    "def predict(modelo_elegido, imagen, clases=[], conf=0.5):\n",
    "    # Si se especifican clases, se predicen únicamente las clases indicadas\n",
    "    if clases:\n",
    "        resultados = modelo_elegido.predict(imagen, clases=clases, conf=conf)\n",
    "    else:\n",
    "        # Si no se especifican clases, se predicen todas con la conf dada\n",
    "        resultados = modelo_elegido.predict(imagen, conf=conf)\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b991e3-599b-4053-834b-5babcace5aca",
   "metadata": {},
   "source": [
    "### Dibujar cuadros delimitadores y etiquetas\n",
    "\n",
    "Aqui vamos a utilizar el modelo de YOLO v11 cargado para llamar a la funcion para detectar los objetos y entoces se aplicaran las funciones del modelo para mostrar los resultados visualmente con etiquetas y cuadros alrededor de los objetos detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7061f3f-fabe-4294-abad-9a598b9eb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir y detectar objetos, dibujando cuadros delimitadores y etiquetas\n",
    "def predict_and_detect(modelo_elegido, imagen, clases=[], conf=0.5, grosor_rectangulo=2, grosor_texto=1):\n",
    "    # Realiza la predicción sobre la imagen\n",
    "    resultados = predict(modelo_elegido, imagen, clases, conf=conf)\n",
    "    \n",
    "    for result in resultados:\n",
    "        # Itera sobre cada caja detectada en el resultado\n",
    "        for box in result.boxes:\n",
    "            # Obtiene la clase del objeto detectado\n",
    "            cls = box.cls[0]\n",
    "            # Obtiene el nombre de la clase detectada\n",
    "            nombre = result.names[int(cls)]\n",
    "            confianza_porcentaje = box.conf[0] * 100\n",
    "            print(f\"{confianza_porcentaje:.2f}%\")\n",
    "            print(nombre) \n",
    "            \n",
    "    # Dibuja un rectángulo en la imagen alrededor del objeto detectado\n",
    "            cv2.rectangle(imagen, (int(box.xyxy[0][0]), int(box.xyxy[0][1])),\n",
    "                          (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (255, 0, 0), grosor_rectangulo)\n",
    "            # Añade una etiqueta con el nombre del objeto detectado encima del rectángulo\n",
    "            cv2.putText(imagen, f\"{result.names[int(box.cls[0])]} ({confianza_porcentaje:.2f}%)\",\n",
    "                        (int(box.xyxy[0][0]), int(box.xyxy[0][1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), grosor_texto)\n",
    "    return imagen, resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ccc39-53c8-4288-b614-1fde7f3da7f3",
   "metadata": {},
   "source": [
    "### Cargar modelo\n",
    "Aqui indicamos el modelo a usar.\n",
    "Pueden encontrar mas sobre los modelos en el Github:\n",
    "https://github.com/ultralytics/ultralytics\n",
    "\n",
    "Ejemplos:\n",
    "- yolo11n.pt - Es el mas ligero\n",
    "- yolo11x.pt - Es el mas pesado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb685310-7d09-4fa2-ab08-b0cde109526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el modelo YOLO con el archivo \"yolo11x.pt\"\n",
    "model = YOLO(\"yolo11x.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b40a0e-16c5-4da3-98ec-cc34f8771a22",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d070e75-27f2-48b6-9580-82a447b33738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 4 horses, 25 sheeps, 465.3ms\n",
      "Speed: 12.3ms preprocess, 465.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "92.86%\n",
      "horse\n",
      "92.21%\n",
      "horse\n",
      "91.03%\n",
      "horse\n",
      "80.73%\n",
      "sheep\n",
      "78.78%\n",
      "horse\n",
      "78.40%\n",
      "sheep\n",
      "75.98%\n",
      "sheep\n",
      "72.30%\n",
      "sheep\n",
      "72.11%\n",
      "sheep\n",
      "72.07%\n",
      "sheep\n",
      "64.27%\n",
      "sheep\n",
      "57.70%\n",
      "sheep\n",
      "48.33%\n",
      "sheep\n",
      "35.67%\n",
      "sheep\n",
      "35.19%\n",
      "sheep\n",
      "30.85%\n",
      "sheep\n",
      "30.47%\n",
      "sheep\n",
      "22.51%\n",
      "sheep\n",
      "21.18%\n",
      "sheep\n",
      "19.89%\n",
      "sheep\n",
      "19.28%\n",
      "sheep\n",
      "18.84%\n",
      "sheep\n",
      "17.61%\n",
      "sheep\n",
      "15.45%\n",
      "sheep\n",
      "13.69%\n",
      "sheep\n",
      "12.29%\n",
      "sheep\n",
      "11.94%\n",
      "sheep\n",
      "11.36%\n",
      "sheep\n",
      "10.81%\n",
      "sheep\n"
     ]
    }
   ],
   "source": [
    "Nombre_de_la_imagen = \"algunos-caballos-y-cientos-de-ovejas-reunidas-en-el-réttir-anual-de-islandia.jpg\"\n",
    "# Lee la imagen desde el archivo \"zidane.jpg\"\n",
    "image = cv2.imread(Nombre_de_la_imagen)\n",
    "# Realiza la predicción y detección sobre la imagen\n",
    "result_img, _ = predict_and_detect(model, image, clases=[], conf=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eaabc5-e2ff-4c09-9a02-d3fa3d1e3466",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7763dd6-68df-4cac-906e-8e50b35fdb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda la imagen resultante en un archivo\n",
    "if result_img is not None:\n",
    "    cv2.imwrite(\"result_\"+Nombre_de_la_imagen , result_img)\n",
    "    # Muestra la imagen resultante con las detecciones\n",
    "    cv2.imshow(\"Resultado\", result_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: result_img is None.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70381cf-8080-4276-b97f-63744963bae7",
   "metadata": {},
   "source": [
    "## Arduino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67b907-71e8-4e44-b9eb-d4e5032d33f0",
   "metadata": {},
   "source": [
    "### Instalar Pyserial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e0f0ed-648b-4732-98d9-b675f0c1b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyserial in c:\\users\\pjrio\\anaconda3\\envs\\yolov11\\lib\\site-packages (3.5)\n"
     ]
    }
   ],
   "source": [
    "# instalar libreria para conectarnos por serial \n",
    "!pip install pyserial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c291a6-086e-4c19-8d34-14c0b200b6e6",
   "metadata": {},
   "source": [
    "### Importar librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fef3653-fdc7-4d56-bb93-7dd65862bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59378f5e-c833-4bae-bcdc-39c915756af6",
   "metadata": {},
   "source": [
    "### Prueba simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34ac5d65-f009-4c73-8fa4-75198148f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "Puerto = \"COM8\"\n",
    "# Configuración del puerto serial (ajusta el puerto a tu configuración)\n",
    "arduino = serial.Serial(port=Puerto, baudrate=921600, timeout=1)\n",
    "\n",
    "time.sleep(2)  # Esperar a que Arduino esté listo\n",
    "\n",
    "def enviar_comando(comando):\n",
    "    arduino.write(f\"{comando}\\n\".encode())  # Enviar comando\n",
    "    time.sleep(0.5)  # Esperar por la respuesta\n",
    "    respuesta = arduino.readline().decode().strip()  # Leer respuesta\n",
    "    print(f\"Respuesta de Arduino: {respuesta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90d9cc0f-4e1c-4ffd-b1c8-2586dccac9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta de Arduino: LED is OFF\n",
      "Respuesta de Arduino: LED is ON\n",
      "Respuesta de Arduino: LED is OFF\n",
      "Respuesta de Arduino: LED is ON\n"
     ]
    }
   ],
   "source": [
    "# Enviar comandos\n",
    "enviar_comando(\"on\")   # Encender LED\n",
    "time.sleep(2)           # Esperar 2 segundos\n",
    "enviar_comando(\"off\")  # Apagar LED\n",
    "time.sleep(2)\n",
    "enviar_comando(\"gato\")   # Encender LED\n",
    "time.sleep(2)\n",
    "enviar_comando(\"dog\")   # Encender LED\n",
    "\n",
    "# Cerrar la conexión al final\n",
    "arduino.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff0515-aa5d-415d-aaeb-fd17a8ddf89a",
   "metadata": {},
   "source": [
    "### Funcion de deteccion y envio de informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957ee1dd-26ab-4315-9b3e-a26ffe463ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir y detectar objetos, dibujando cuadros delimitadores y etiquetas\n",
    "def predict_and_detect(modelo_elegido, imagen, clases=[], conf=0.5, grosor_rectangulo=2, grosor_texto=1):\n",
    "    # Realiza la predicción sobre la imagen\n",
    "    resultados = predict(modelo_elegido, imagen, clases, conf=conf)\n",
    "    \n",
    "    for result in resultados:\n",
    "        # Itera sobre cada caja detectada en el resultado\n",
    "        for box in result.boxes:\n",
    "            # Obtiene la clase del objeto detectado\n",
    "            cls = box.cls[0]\n",
    "            # Obtiene el nombre de la clase detectada\n",
    "            nombre = classNames[int(cls)]\n",
    "            confianza_porcentaje = box.conf[0] * 100\n",
    "            print(f\"{confianza_porcentaje:.2f}%\")\n",
    "            print(nombre) \n",
    "\n",
    "            if nombre == \"gato\":\n",
    "                enviar_comando(\"gato\")   # Encender LED\n",
    "            \n",
    "    # Dibuja un rectángulo en la imagen alrededor del objeto detectado\n",
    "            cv2.rectangle(imagen, (int(box.xyxy[0][0]), int(box.xyxy[0][1])),\n",
    "                          (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (255, 0, 0), grosor_rectangulo)\n",
    "            # Añade una etiqueta con el nombre del objeto detectado encima del rectángulo\n",
    "            cv2.putText(imagen, f\"{result.names[int(box.cls[0])]} ({confianza_porcentaje:.2f}%)\",\n",
    "                        (int(box.xyxy[0][0]), int(box.xyxy[0][1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), grosor_texto)\n",
    "    return imagen, resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4e785e4-6a4d-4f7f-9602-6a609f3c84ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 320x640 2 cats, 3 dogs, 406.9ms\n",
      "Speed: 2.0ms preprocess, 406.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
      "92.81%\n",
      "perro\n",
      "92.68%\n",
      "gato\n",
      "Respuesta de Arduino: LED is OFF\n",
      "90.55%\n",
      "perro\n",
      "90.22%\n",
      "gato\n",
      "Respuesta de Arduino: LED is ON\n",
      "89.80%\n",
      "perro\n"
     ]
    }
   ],
   "source": [
    "Nombre_de_la_imagen = \"-703-2048x1070-0.jpg\"\n",
    "# Lee la imagen desde el archivo \"zidane.jpg\"\n",
    "image = cv2.imread(Nombre_de_la_imagen)\n",
    "# Realiza la predicción y detección sobre la imagen\n",
    "result_img, _ = predict_and_detect(model, image, clases=[], conf=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4023f-7b53-4912-a16d-5d4092862d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda la imagen resultante en un archivo\n",
    "if result_img is not None:\n",
    "    cv2.imwrite(\"result_\"+Nombre_de_la_imagen , result_img)\n",
    "    # Muestra la imagen resultante con las detecciones\n",
    "    cv2.imshow(\"Resultado\", result_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Error: result_img is None.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbe6338-96ad-4a98-a68e-605bb4a3473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 760.3ms\n",
      "Speed: 0.0ms preprocess, 760.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "95.81%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 727.2ms\n",
      "Speed: 0.0ms preprocess, 727.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.09%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 711.7ms\n",
      "Speed: 0.0ms preprocess, 711.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.64%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 720.4ms\n",
      "Speed: 0.0ms preprocess, 720.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.73%\n",
      "persona\n",
      "69.55%\n",
      "corbata\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 713.2ms\n",
      "Speed: 0.0ms preprocess, 713.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.69%\n",
      "persona\n",
      "53.21%\n",
      "corbata\n",
      "\n",
      "0: 480x640 1 person, 700.5ms\n",
      "Speed: 2.5ms preprocess, 700.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.62%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 712.5ms\n",
      "Speed: 0.0ms preprocess, 712.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.92%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 604.1ms\n",
      "Speed: 0.0ms preprocess, 604.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.66%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 596.7ms\n",
      "Speed: 0.0ms preprocess, 596.7ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.69%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 596.6ms\n",
      "Speed: 0.0ms preprocess, 596.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.68%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 580.1ms\n",
      "Speed: 0.0ms preprocess, 580.1ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.58%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 586.8ms\n",
      "Speed: 0.0ms preprocess, 586.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.58%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 588.1ms\n",
      "Speed: 0.0ms preprocess, 588.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.47%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 591.6ms\n",
      "Speed: 0.0ms preprocess, 591.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.30%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 590.7ms\n",
      "Speed: 0.0ms preprocess, 590.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.68%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 604.5ms\n",
      "Speed: 0.0ms preprocess, 604.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.91%\n",
      "persona\n",
      "\n",
      "0: 480x640 1 person, 629.0ms\n",
      "Speed: 0.0ms preprocess, 629.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "96.76%\n",
      "persona\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame from webcam.\")\n",
    "        break\n",
    "\n",
    "    # Perform object detection using the existing function\n",
    "    frame, _ = predict_and_detect(model, frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow(\"YOLO v11 Webcam Detection\", frame)\n",
    "\n",
    "    # Press 'q' to quit the webcam stream\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "964aab2b-2a4e-4c1d-acfb-2b3c4295c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 65.4ms\n",
      "Speed: 8.2ms preprocess, 65.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.27203369140625, 45.74395751953125, 528.9157104492188, 479.21490478515625]]\n",
      "\n",
      "0: 480x640 1 person, 65.5ms\n",
      "Speed: 0.0ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[5.48773193359375, 46.46453857421875, 528.8259887695312, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 65.3ms\n",
      "Speed: 0.0ms preprocess, 65.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.90, BBox: [[10.30816650390625, 46.7596435546875, 528.7486572265625, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.42, BBox: [[329.9822998046875, 326.2760009765625, 388.01812744140625, 394.4921875]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 64.8ms\n",
      "Speed: 0.0ms preprocess, 64.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[1.12689208984375, 45.6912841796875, 528.0902099609375, 479.24652099609375]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.43, BBox: [[329.69342041015625, 321.7894287109375, 388.34625244140625, 395.177734375]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 62.8ms\n",
      "Speed: 2.0ms preprocess, 62.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[0.7340087890625, 46.15069580078125, 522.2507934570312, 479.3426513671875]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.35, BBox: [[329.41448974609375, 319.4158935546875, 387.80419921875, 394.04254150390625]]\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 65.0ms\n",
      "Speed: 0.0ms preprocess, 65.0ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.8873291015625, 46.548248291015625, 529.1055297851562, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.38, BBox: [[270.3443603515625, 323.92803955078125, 402.24554443359375, 479.7216796875]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.36, BBox: [[330.18402099609375, 324.09381103515625, 387.30950927734375, 394.16326904296875]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 72.9ms\n",
      "Speed: 0.0ms preprocess, 72.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[3.83367919921875, 45.909942626953125, 528.7377319335938, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.26, BBox: [[255.28128051757812, 371.85748291015625, 292.3987121582031, 476.17291259765625]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 66.1ms\n",
      "Speed: 0.0ms preprocess, 66.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[3.169677734375, 45.788116455078125, 528.649169921875, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.40, BBox: [[328.796875, 320.4375, 387.90869140625, 393.9578857421875]]\n",
      "\n",
      "0: 480x640 1 person, 64.6ms\n",
      "Speed: 0.0ms preprocess, 64.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[2.9415283203125, 45.40594482421875, 528.520263671875, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 65.1ms\n",
      "Speed: 0.0ms preprocess, 65.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[1.7109375, 45.60235595703125, 528.1239013671875, 478.79241943359375]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.35, BBox: [[258.29949951171875, 321.92413330078125, 385.65960693359375, 479.53924560546875]]\n",
      "\n",
      "0: 480x640 1 person, 65.2ms\n",
      "Speed: 0.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.42059326171875, 45.03901672363281, 523.6760864257812, 479.27569580078125]]\n",
      "\n",
      "0: 480x640 1 person, 64.2ms\n",
      "Speed: 0.0ms preprocess, 64.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[3.43890380859375, 45.703125, 528.6818237304688, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 65.2ms\n",
      "Speed: 0.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[4.089111328125, 44.9669189453125, 528.0515747070312, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 71.3ms\n",
      "Speed: 0.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[0.53009033203125, 44.63238525390625, 527.6444091796875, 479.11883544921875]]\n",
      "\n",
      "0: 480x640 1 person, 65.0ms\n",
      "Speed: 0.0ms preprocess, 65.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[0.59283447265625, 45.33599853515625, 527.3222045898438, 478.81890869140625]]\n",
      "\n",
      "0: 480x640 1 person, 81.0ms\n",
      "Speed: 0.0ms preprocess, 81.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.61871337890625, 43.82232666015625, 527.8584594726562, 479.95892333984375]]\n",
      "\n",
      "0: 480x640 1 person, 2 ties, 73.3ms\n",
      "Speed: 0.0ms preprocess, 73.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[0.66259765625, 43.885772705078125, 525.9898681640625, 479.0469055175781]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.39, BBox: [[270.08758544921875, 327.89703369140625, 398.52880859375, 479.67596435546875]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.33, BBox: [[252.88450622558594, 370.5519104003906, 293.140869140625, 475.5285949707031]]\n",
      "\n",
      "0: 480x640 1 person, 65.3ms\n",
      "Speed: 0.0ms preprocess, 65.3ms inference, 8.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[1.52386474609375, 43.16264343261719, 527.1439208984375, 479.03363037109375]]\n",
      "\n",
      "0: 480x640 1 person, 72.7ms\n",
      "Speed: 0.0ms preprocess, 72.7ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[2.02008056640625, 43.86175537109375, 527.1670532226562, 478.8255615234375]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 64.9ms\n",
      "Speed: 0.0ms preprocess, 64.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[3.014892578125, 42.7327880859375, 527.053466796875, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.30, BBox: [[250.44813537597656, 324.68505859375, 385.1966552734375, 469.723388671875]]\n",
      "\n",
      "0: 480x640 1 person, 65.5ms\n",
      "Speed: 0.0ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[0.765380859375, 42.49482727050781, 526.8013916015625, 478.99652099609375]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 1 cell phone, 65.5ms\n",
      "Speed: 0.0ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.7772216796875, 42.19549560546875, 527.152587890625, 480.0]]\n",
      "Name: cell phone\n",
      "Class: 67, Confidence: 0.28, BBox: [[202.49549865722656, 193.34259033203125, 251.03648376464844, 274.83673095703125]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.26, BBox: [[269.25469970703125, 323.087646484375, 409.26025390625, 479.7254638671875]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 65.2ms\n",
      "Speed: 0.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.303466796875, 42.07975769042969, 527.4288330078125, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.32, BBox: [[252.0443115234375, 372.28741455078125, 291.910400390625, 474.97906494140625]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 83.5ms\n",
      "Speed: 0.0ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[0.47039794921875, 42.331817626953125, 526.310791015625, 479.0575866699219]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.46, BBox: [[253.8880615234375, 373.7370300292969, 291.27032470703125, 470.6440734863281]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 81.5ms\n",
      "Speed: 0.0ms preprocess, 81.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[0.73748779296875, 42.99650573730469, 526.638916015625, 479.13897705078125]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.43, BBox: [[269.866943359375, 319.6341552734375, 403.067138671875, 479.7132568359375]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 65.2ms\n",
      "Speed: 0.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[1.06793212890625, 42.4210205078125, 527.6524658203125, 479.22119140625]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.27, BBox: [[328.84271240234375, 322.63775634765625, 387.72393798828125, 396.29278564453125]]\n",
      "\n",
      "0: 480x640 1 person, 74.4ms\n",
      "Speed: 0.0ms preprocess, 74.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.93, BBox: [[0.79931640625, 41.59864807128906, 527.1156005859375, 479.043212890625]]\n",
      "\n",
      "0: 480x640 1 person, 82.2ms\n",
      "Speed: 0.0ms preprocess, 82.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[1.65948486328125, 39.93180847167969, 526.3651733398438, 479.01397705078125]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 73.3ms\n",
      "Speed: 0.0ms preprocess, 73.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[7.02978515625, 36.69450378417969, 527.8203125, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.46, BBox: [[257.40301513671875, 373.01947021484375, 294.5771484375, 473.82989501953125]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 70.1ms\n",
      "Speed: 3.5ms preprocess, 70.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[7.02978515625, 36.69450378417969, 527.8203125, 480.0]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.46, BBox: [[257.40301513671875, 373.01947021484375, 294.5771484375, 473.82989501953125]]\n",
      "\n",
      "0: 480x640 1 person, 73.4ms\n",
      "Speed: 0.0ms preprocess, 73.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.3255615234375, 34.6627197265625, 525.5147705078125, 479.1162109375]]\n",
      "\n",
      "0: 480x640 1 person, 90.7ms\n",
      "Speed: 0.0ms preprocess, 90.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.88, BBox: [[2.47607421875, 30.896240234375, 526.6109619140625, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 73.8ms\n",
      "Speed: 0.0ms preprocess, 73.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[3.03631591796875, 27.585174560546875, 525.8433837890625, 479.22320556640625]]\n",
      "\n",
      "0: 480x640 1 person, 81.8ms\n",
      "Speed: 0.0ms preprocess, 81.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.93, BBox: [[2.81640625, 26.605133056640625, 524.4742431640625, 479.313232421875]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 72.9ms\n",
      "Speed: 0.0ms preprocess, 72.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[2.53759765625, 20.66131591796875, 524.3140869140625, 479.83050537109375]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.42, BBox: [[265.80316162109375, 321.10308837890625, 395.43927001953125, 479.72357177734375]]\n",
      "\n",
      "0: 480x640 1 person, 65.5ms\n",
      "Speed: 0.0ms preprocess, 65.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.94805908203125, 20.22064208984375, 523.9389038085938, 479.88311767578125]]\n",
      "\n",
      "0: 480x640 1 person, 81.7ms\n",
      "Speed: 0.0ms preprocess, 81.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.231689453125, 17.5399169921875, 518.3848876953125, 479.44488525390625]]\n",
      "\n",
      "0: 480x640 1 person, 73.3ms\n",
      "Speed: 0.0ms preprocess, 73.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[2.5133056640625, 18.209625244140625, 523.085205078125, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 80.5ms\n",
      "Speed: 0.0ms preprocess, 80.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.90, BBox: [[2.63348388671875, 17.809722900390625, 523.9869384765625, 479.292724609375]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.34, BBox: [[239.74688720703125, 376.76470947265625, 284.3126220703125, 478.203369140625]]\n",
      "\n",
      "0: 480x640 1 person, 65.1ms\n",
      "Speed: 0.0ms preprocess, 65.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[3.95587158203125, 16.936614990234375, 523.4390258789062, 479.8114013671875]]\n",
      "\n",
      "0: 480x640 1 person, 72.8ms\n",
      "Speed: 0.0ms preprocess, 72.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[3.46832275390625, 17.61358642578125, 523.9768676757812, 479.09210205078125]]\n",
      "\n",
      "0: 480x640 1 person, 72.2ms\n",
      "Speed: 0.0ms preprocess, 72.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.0345458984375, 16.8572998046875, 518.2215576171875, 479.0777893066406]]\n",
      "\n",
      "0: 480x640 1 person, 73.7ms\n",
      "Speed: 0.0ms preprocess, 73.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.23443603515625, 16.16717529296875, 519.2573852539062, 479.7303771972656]]\n",
      "\n",
      "0: 480x640 1 person, 90.2ms\n",
      "Speed: 0.0ms preprocess, 90.2ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[1.0751953125, 17.230865478515625, 519.0049438476562, 479.8977355957031]]\n",
      "\n",
      "0: 480x640 1 person, 73.7ms\n",
      "Speed: 0.0ms preprocess, 73.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[3.14056396484375, 17.00732421875, 523.1820068359375, 479.2108459472656]]\n",
      "\n",
      "0: 480x640 1 person, 81.9ms\n",
      "Speed: 0.0ms preprocess, 81.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[3.935302734375, 18.9517822265625, 523.3238525390625, 479.21783447265625]]\n",
      "\n",
      "0: 480x640 1 person, 73.5ms\n",
      "Speed: 0.0ms preprocess, 73.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[4.06640625, 20.797027587890625, 520.058349609375, 479.7160339355469]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 89.4ms\n",
      "Speed: 0.0ms preprocess, 89.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[2.425537109375, 21.403350830078125, 520.9049072265625, 479.1921081542969]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.60, BBox: [[223.21197509765625, 370.06976318359375, 288.43780517578125, 477.80914306640625]]\n",
      "\n",
      "0: 480x640 1 person, 73.2ms\n",
      "Speed: 0.0ms preprocess, 73.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.93, BBox: [[8.92041015625, 21.067901611328125, 519.7977294921875, 479.2660827636719]]\n",
      "\n",
      "0: 480x640 1 person, 73.6ms\n",
      "Speed: 0.0ms preprocess, 73.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[4.90185546875, 21.70819091796875, 520.6563720703125, 479.57708740234375]]\n",
      "\n",
      "0: 480x640 1 person, 64.8ms\n",
      "Speed: 0.0ms preprocess, 64.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[3.131103515625, 20.8997802734375, 520.0550537109375, 479.3025817871094]]\n",
      "\n",
      "0: 480x640 1 person, 65.1ms\n",
      "Speed: 0.0ms preprocess, 65.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[0.9144287109375, 21.247711181640625, 511.7113037109375, 479.7868347167969]]\n",
      "\n",
      "0: 480x640 1 person, 65.0ms\n",
      "Speed: 0.0ms preprocess, 65.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.950927734375, 20.596435546875, 516.88720703125, 479.6715087890625]]\n",
      "\n",
      "0: 480x640 1 person, 65.6ms\n",
      "Speed: 0.0ms preprocess, 65.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[8.58282470703125, 19.750457763671875, 517.953125, 479.39703369140625]]\n",
      "\n",
      "0: 480x640 1 person, 65.3ms\n",
      "Speed: 0.0ms preprocess, 65.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.78375244140625, 21.35577392578125, 516.1782836914062, 480.0]]\n",
      "\n",
      "0: 480x640 1 person, 79.5ms\n",
      "Speed: 2.5ms preprocess, 79.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[6.7735595703125, 19.812408447265625, 517.2615966796875, 479.3199462890625]]\n",
      "\n",
      "0: 480x640 1 person, 65.6ms\n",
      "Speed: 0.0ms preprocess, 65.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.78594970703125, 20.945892333984375, 515.5214233398438, 479.7708435058594]]\n",
      "\n",
      "0: 480x640 1 person, 65.2ms\n",
      "Speed: 0.0ms preprocess, 65.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[3.91204833984375, 20.871917724609375, 516.4389038085938, 479.15789794921875]]\n",
      "\n",
      "0: 480x640 1 person, 64.3ms\n",
      "Speed: 0.0ms preprocess, 64.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[2.6932373046875, 21.069000244140625, 515.208251953125, 479.38812255859375]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 57.1ms\n",
      "Speed: 0.0ms preprocess, 57.1ms inference, 8.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[5.3697509765625, 19.86297607421875, 515.4752197265625, 479.18988037109375]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.41, BBox: [[239.7109832763672, 369.74700927734375, 286.29205322265625, 478.15557861328125]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 65.3ms\n",
      "Speed: 0.0ms preprocess, 65.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.93, BBox: [[3.4761810302734375, 21.0057373046875, 514.71044921875, 479.42474365234375]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.36, BBox: [[244.2315673828125, 370.227294921875, 285.712646484375, 477.775634765625]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 66.4ms\n",
      "Speed: 0.0ms preprocess, 66.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.92, BBox: [[5.3639678955078125, 19.860626220703125, 516.3206176757812, 479.1561279296875]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.30, BBox: [[245.71871948242188, 364.78387451171875, 330.9078674316406, 477.25067138671875]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 64.8ms\n",
      "Speed: 0.0ms preprocess, 64.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[5.65411376953125, 20.576904296875, 522.9793701171875, 479.199951171875]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.51, BBox: [[247.3688201904297, 369.18157958984375, 287.41571044921875, 478.62042236328125]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 64.5ms\n",
      "Speed: 0.0ms preprocess, 64.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.90, BBox: [[9.68408203125, 21.02227783203125, 539.9541015625, 479.203125]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.25, BBox: [[217.786865234375, 369.0751953125, 287.68096923828125, 475.56591796875]]\n",
      "\n",
      "0: 480x640 1 person, 79.1ms\n",
      "Speed: 0.0ms preprocess, 79.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.91, BBox: [[4.54168701171875, 19.0472412109375, 544.9138793945312, 479.23370361328125]]\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 62.0ms\n",
      "Speed: 2.0ms preprocess, 62.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Name: person\n",
      "Class: 0, Confidence: 0.89, BBox: [[6.86083984375, 18.32708740234375, 555.2775268554688, 479.0523681640625]]\n",
      "Name: tie\n",
      "Class: 27, Confidence: 0.43, BBox: [[235.44488525390625, 370.91156005859375, 288.16973876953125, 472.49639892578125]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv11 model (use your model path here)\n",
    "model = YOLO(\"yolo11n.pt\")  # Update with your model's actual path\n",
    "\n",
    "# Open the webcam\n",
    "cap = cv2.VideoCapture(0)  # '0' selects the default webcam\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "# Read frames in a loop\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to read frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        # Run YOLO on the frame\n",
    "        results = model(frame)  # Perform inference\n",
    "\n",
    "        # Print detection details\n",
    "        for result in results:\n",
    "            for box in result.boxes:\n",
    "                class_id = int(box.cls)  # Convert tensor to int\n",
    "                confidence = float(box.conf)  # Convert tensor to float\n",
    "                bbox = box.xyxy.tolist()  # Convert tensor to list\n",
    "                name = result.names[int(class_id)]\n",
    "                # Print detection information\n",
    "                print(\"Name: \" + name + \"\")\n",
    "                print(f\"Class: {class_id}, Confidence: {confidence:.2f}, BBox: {bbox}\")\n",
    "\n",
    "        # Draw the results on the frame\n",
    "        annotated_frame = results[0].plot()  # Annotate the frame with detections\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv11 Webcam\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    # Release the webcam and close all OpenCV windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e81b25-7353-4960-881c-ff40b67ae98f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
